{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf2e8825-b1d2-4c6d-81ee-75c05f88d00c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Traffic Crash Analysis\n",
    "\n",
    "### Data importing and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3229176b-3990-44da-9583-71919c5cd60e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Make the GET request\n",
    "resp = requests.get('https://data.cityofchicago.org/resource/85ca-t3if.json?$query=SELECT%20crash_record_id%2C%20crash_date_est_i%2C%20crash_date%2C%20posted_speed_limit%2C%20traffic_control_device%2C%20device_condition%2C%20weather_condition%2C%20lighting_condition%2C%20first_crash_type%2C%20trafficway_type%2C%20lane_cnt%2C%20alignment%2C%20roadway_surface_cond%2C%20road_defect%2C%20report_type%2C%20crash_type%2C%20intersection_related_i%2C%20private_property_i%2C%20hit_and_run_i%2C%20damage%2C%20date_police_notified%2C%20prim_contributory_cause%2C%20sec_contributory_cause%2C%20street_no%2C%20street_direction%2C%20street_name%2C%20beat_of_occurrence%2C%20photos_taken_i%2C%20statements_taken_i%2C%20dooring_i%2C%20work_zone_i%2C%20work_zone_type%2C%20workers_present_i%2C%20num_units%2C%20most_severe_injury%2C%20injuries_total%2C%20injuries_fatal%2C%20injuries_incapacitating%2C%20injuries_non_incapacitating%2C%20injuries_reported_not_evident%2C%20injuries_no_indication%2C%20injuries_unknown%2C%20crash_hour%2C%20crash_day_of_week%2C%20crash_month%2C%20latitude%2C%20longitude%2C%20location%20ORDER%20BY%20crash_date%20DESC%2C%20crash_record_id%20ASC')\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"SENG550\").getOrCreate()\n",
    "\n",
    "# Create a Spark DataFrame from the response text\n",
    "df2 = spark.read.json(spark.sparkContext.parallelize([resp.text]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eb8512f-928f-45de-8a07-38be8594f2e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------------------+----------------+-----------------+----------+-----------+--------------------+--------------------+-------------+--------------------+--------------------+---------+--------------------+-------------+--------------+-----------------------+----------------------+---------------------------+-----------------------------+--------------+----------------+----------------------+------------+--------------------+--------------------+-------------+--------------------+---------+--------------+------------------+-----------------------+------------------+--------------------+-----------+--------------------+----------------------+------------------+----------------+-----------+---------+----------------------+---------------+-----------------+-----------+--------------+-----------------+\n|         alignment|beat_of_occurrence|          crash_date|crash_date_est_i|crash_day_of_week|crash_hour|crash_month|     crash_record_id|          crash_type|       damage|date_police_notified|    device_condition|dooring_i|    first_crash_type|hit_and_run_i|injuries_fatal|injuries_incapacitating|injuries_no_indication|injuries_non_incapacitating|injuries_reported_not_evident|injuries_total|injuries_unknown|intersection_related_i|    latitude|  lighting_condition|            location|    longitude|  most_severe_injury|num_units|photos_taken_i|posted_speed_limit|prim_contributory_cause|private_property_i|         report_type|road_defect|roadway_surface_cond|sec_contributory_cause|statements_taken_i|street_direction|street_name|street_no|traffic_control_device|trafficway_type|weather_condition|work_zone_i|work_zone_type|workers_present_i|\n+------------------+------------------+--------------------+----------------+-----------------+----------+-----------+--------------------+--------------------+-------------+--------------------+--------------------+---------+--------------------+-------------+--------------+-----------------------+----------------------+---------------------------+-----------------------------+--------------+----------------+----------------------+------------+--------------------+--------------------+-------------+--------------------+---------+--------------+------------------+-----------------------+------------------+--------------------+-----------+--------------------+----------------------+------------------+----------------+-----------+---------+----------------------+---------------+-----------------+-----------+--------------+-----------------+\n|STRAIGHT AND LEVEL|              2522|2023-12-10T00:40:...|            null|                1|         0|         12|62bda678909052a25...|NO INJURY / DRIVE...|  OVER $1,500|2023-12-10T01:20:...|         NO CONTROLS|     null|PARKED MOTOR VEHICLE|            Y|             0|                      0|                     1|                          0|                            0|             0|               0|                  null|41.918734001|DARKNESS, LIGHTED...|{[-87.73914755614...|-87.739147556|NO INDICATION OF ...|        4|          null|                30|    UNABLE TO DETERMINE|              null|            ON SCENE| NO DEFECTS|                 DRY|   UNABLE TO DETERMINE|              null|               W|DICKENS AVE|     4507|           NO CONTROLS|    NOT DIVIDED|            CLEAR|       null|          null|             null|\n|STRAIGHT AND LEVEL|               124|2023-12-10T00:38:...|            null|                1|         0|         12|8a688454d69efe4e8...|NO INJURY / DRIVE...|$501 - $1,500|2023-12-10T00:40:...|         NO CONTROLS|     null|               ANGLE|         null|             0|                      0|                     3|                          0|                            0|             0|               0|                  null|41.869855597|DARKNESS, LIGHTED...|{[-87.64027030786...|-87.640270308|NO INDICATION OF ...|        2|          null|                10|   DISTRACTION - FRO...|                 Y|            ON SCENE|    UNKNOWN|             UNKNOWN|  DRIVING SKILLS/KN...|              null|               W|  TAYLOR ST|      520|           NO CONTROLS|    PARKING LOT|            CLEAR|       null|          null|             null|\n|STRAIGHT AND LEVEL|               222|2023-12-09T23:00:...|            null|                7|        23|         12|ae9c28fad1431059b...|INJURY AND / OR T...|  OVER $1,500|2023-12-09T23:16:...|         NO CONTROLS|     null|        FIXED OBJECT|         null|             0|                      0|                     2|                          0|                            0|             0|               0|                     Y|41.816761721|DARKNESS, LIGHTED...|{[-87.60178731861...|-87.601787319|NO INDICATION OF ...|        1|          null|                30|   CELL PHONE USE OT...|              null|            ON SCENE| NO DEFECTS|                 DRY|        NOT APPLICABLE|              null|               E|    43RD ST|     1001|           NO CONTROLS| L-INTERSECTION|            CLEAR|       null|          null|             null|\n|STRAIGHT AND LEVEL|              1724|2023-12-09T22:50:...|            null|                7|        22|         12|238058536a3d1999e...|NO INJURY / DRIVE...|$501 - $1,500|2023-12-09T23:10:...|FUNCTIONING PROPERLY|     null|SIDESWIPE SAME DI...|         null|             0|                      0|                     2|                          0|                            0|             0|               0|                  null|41.953908218|DARKNESS, LIGHTED...|{[-87.71276017801...|-87.712760178|NO INDICATION OF ...|        2|          null|                30|    UNABLE TO DETERMINE|              null|NOT ON SCENE (DES...|    UNKNOWN|                 DRY|   UNABLE TO DETERMINE|              null|               N|KIMBALL AVE|     4001|        TRAFFIC SIGNAL|    NOT DIVIDED|            CLEAR|       null|          null|             null|\n|STRAIGHT AND LEVEL|              2411|2023-12-09T21:24:...|            null|                7|        21|         12|c438fc5583220a106...|NO INJURY / DRIVE...|  OVER $1,500|2023-12-09T21:25:...|         NO CONTROLS|     null|PARKED MOTOR VEHICLE|         null|             0|                      0|                     1|                          0|                            0|             0|               0|                  null|42.017798707|            DARKNESS|{[-87.68459246939...|-87.684592469|NO INDICATION OF ...|        2|          null|                30|    UNABLE TO DETERMINE|              null|            ON SCENE| NO DEFECTS|                 DRY|   UNABLE TO DETERMINE|              null|               N| RIDGE BLVD|     7500|           NO CONTROLS|          ALLEY|            CLEAR|       null|          null|             null|\n+------------------+------------------+--------------------+----------------+-----------------+----------+-----------+--------------------+--------------------+-------------+--------------------+--------------------+---------+--------------------+-------------+--------------+-----------------------+----------------------+---------------------------+-----------------------------+--------------+----------------+----------------------+------------+--------------------+--------------------+-------------+--------------------+---------+--------------+------------------+-----------------------+------------------+--------------------+-----------+--------------------+----------------------+------------------+----------------+-----------+---------+----------------------+---------------+-----------------+-----------+--------------+-----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Show the DataFrame\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9fad5a2-1613-4cec-ae8e-1d128510cfbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create RDD of wanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d16fd3f-6dba-4801-8d28-537a47d1759f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----------------+--------------------+--------------------+-------------+------------+\n|          Crash_type|num_units|Weather_condition|          Crash_date|  Most_severe_injury|    Longitude|    Latitude|\n+--------------------+---------+-----------------+--------------------+--------------------+-------------+------------+\n|NO INJURY / DRIVE...|        4|            CLEAR|2023-12-10T00:40:...|NO INDICATION OF ...|-87.739147556|41.918734001|\n+--------------------+---------+-----------------+--------------------+--------------------+-------------+------------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "wanted_columns = df2.select(\"Crash_type\",\"num_units\",\"Weather_condition\",\"Crash_date\",\"Most_severe_injury\",\"Longitude\",\"Latitude\")\n",
    "wanted_columns.show(1)\n",
    "rdd_of_features = wanted_columns.rdd.map(lambda row:[row[0],row[1],row[2],row[3],row[4],row[5],row[6]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04cf460a-c0c5-4d25-b736-79f06b69fc19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Remove all rows where the content of one of the fields is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd8e8d5e-837d-4d7f-b335-4099e24b27db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n919\n"
     ]
    }
   ],
   "source": [
    "print(rdd_of_features.count())\n",
    "#row[0] = Crash_type, row[2] = Weather_condition,  row[4]= Most_severe_injury\n",
    "cleaned_data_rdd = rdd_of_features.filter(lambda row: row[0]!=\"UNKNOWN\"  and row[2]!=\"UNKNOWN\"  and row[4]!=\"UNKNOWN\" and row[5] != None and row[6] != None and row[0] != None and row[1] != None and row[2] != None and row[3] != None and row[4] != None)\n",
    "print(cleaned_data_rdd.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db499f2b-8f48-4a7d-8fb7-b399b739179d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Dataframe from RDD and get it ready for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b6a14eb-205d-441d-884b-f6aba0d71546",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('_1', 'string'), ('_2', 'string'), ('_3', 'string'), ('_4', 'string'), ('_5', 'string'), ('_6', 'string'), ('_7', 'string')]\n[('_1', 'string'), ('_2', 'double'), ('_3', 'string'), ('_4', 'string'), ('_5', 'string'), ('_6', 'double'), ('_7', 'double')]\n+--------------------+---+-----+--------------------+--------------------+-------------+------------+--------+--------+--------+--------+\n|                  _1| _2|   _3|                  _4|                  _5|           _6|          _7|_1_index|_3_index|_4_index|_5_index|\n+--------------------+---+-----+--------------------+--------------------+-------------+------------+--------+--------+--------+--------+\n|NO INJURY / DRIVE...|4.0|CLEAR|2023-12-10T00:40:...|NO INDICATION OF ...|-87.739147556|41.918734001|     0.0|     0.0|   679.0|     0.0|\n|NO INJURY / DRIVE...|2.0|CLEAR|2023-12-10T00:38:...|NO INDICATION OF ...|-87.640270308|41.869855597|     0.0|     0.0|   678.0|     0.0|\n|INJURY AND / OR T...|1.0|CLEAR|2023-12-09T23:00:...|NO INDICATION OF ...|-87.601787319|41.816761721|     1.0|     0.0|   677.0|     0.0|\n|NO INJURY / DRIVE...|2.0|CLEAR|2023-12-09T22:50:...|NO INDICATION OF ...|-87.712760178|41.953908218|     0.0|     0.0|   676.0|     0.0|\n|NO INJURY / DRIVE...|2.0|CLEAR|2023-12-09T21:24:...|NO INDICATION OF ...|-87.684592469|42.017798707|     0.0|     0.0|   675.0|     0.0|\n+--------------------+---+-----+--------------------+--------------------+-------------+------------+--------+--------+--------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "cleaned_data_df = spark.createDataFrame(cleaned_data_rdd)\n",
    "\n",
    "#_1 = Crash_type, _2 = numUnits, _3 = weather, _4 = time, _5 = injury severity, _6 = longitude, _7 = latitude\n",
    "print(cleaned_data_df.dtypes)\n",
    "numeric_cols = [\"_2\", \"_6\", \"_7\"]\n",
    "for col_name in numeric_cols:    \n",
    "    cleaned_data_df = cleaned_data_df.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "print(cleaned_data_df.dtypes)\n",
    "\n",
    "string_cols = [\"_1\", \"_3\", \"_4\", \"_5\"]\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(cleaned_data_df) for column in string_cols ]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "indexed_df = pipeline.fit(cleaned_data_df).transform(cleaned_data_df)\n",
    "indexed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8198d30-38e7-452a-b063-3bb0fec0e10f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Labeled Points\n",
    "\n",
    "Partially taken from lab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c911718f-e575-4df5-9983-4a77ea6dd0f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "indexed_rdd = indexed_df.rdd\n",
    "print(indexed_rdd.take(1)[0][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e63b46b-d1c4-4968-aefb-c17b5aa0262d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-87.739147556,4.0,41.918734001,0.0,0.0,679.0,0.0']\n[4.0,41.918734001,0.0,0.0,679.0,0.0] -87.739147556\n6\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "def createRDD(values):\n",
    "    return str(values[5]) +',' +str(values[1]) +',' +str(values[6]) +',' +str(values[7]) +',' +str(values[8]) +',' + str(values[9]) +',' + str(values[10])\n",
    "\n",
    "def parsePoint(line):\n",
    "    label_features = line.split(',')\n",
    "    ret_val = LabeledPoint(label_features[0],label_features[1:])\n",
    "    return ret_val\n",
    "\n",
    "indexed_rdd = indexed_df.rdd\n",
    "nice_rdd = indexed_rdd.map(createRDD)\n",
    "print(nice_rdd.take(1))\n",
    "parsedPoints = nice_rdd.map(parsePoint)\n",
    "firstPoint = parsedPoints.take(1)\n",
    "firstPointFeatures =firstPoint[0].features \n",
    "firstPointLabel = firstPoint[0].label\n",
    "print (firstPointFeatures, firstPointLabel)\n",
    "d = len(firstPointFeatures)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "187bc96a-b237-4ef8-9ea2-4442f3f3c240",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Normalize features\n",
    "\n",
    "Taken from lab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a5b83d8-b35e-4230-a88b-ad5a8e13f731",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(-87.739147556, [4.736608919573033,0.6614447817838677,-0.6602556323122132,-0.27573645879954267,1.9570253721791233,-0.3842492869745239]), LabeledPoint(-87.640270308, [-0.09194748318638288,0.09687504293802254,-0.6602556323122132,-0.27573645879954267,1.952293270256998,-0.3842492869745239]), LabeledPoint(-87.601787319, [-2.506225684566091,-0.5163854822549204,1.5145648913255074,-0.27573645879954267,1.9475611683348726,-0.3842492869745239]), LabeledPoint(-87.712760178, [-0.09194748318638288,1.0677243834214338,-0.6602556323122132,-0.27573645879954267,1.942829066412747,-0.3842492869745239]), LabeledPoint(-87.684592469, [-0.09194748318638288,1.8056911281919992,-0.6602556323122132,-0.27573645879954267,1.9380969644906216,-0.3842492869745239])]\n"
     ]
    }
   ],
   "source": [
    "def normalizeFeatures(lp):\n",
    "    \"\"\"Normalizes features in the LabeledPoint object lp.\n",
    "\n",
    "    Args:\n",
    "        lp - LabeledPoint object \n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: The object contains the label and the normalized features\n",
    "    \"\"\"\n",
    "    normalizedFeatures = list()\n",
    "    for i in range(0,len(lp.features)):\n",
    "        feature = (lp.features[i]-broadcastMean.value[i])/broadcastStdev.value[i]\n",
    "        normalizedFeatures.insert(i,feature)\n",
    "    return LabeledPoint(lp.label, normalizedFeatures)\n",
    "    #normalizedAccidents = (lp.features[0]-broadcastMeanAccidents.value)/broadcastStdevAccidents.value\n",
    "    #normalizedSnoOnGround = (lp.features[1]-broadcastMeanSnoOnGround.value)/broadcastStdevSnoOnGround.value\n",
    "    #return LabeledPoint(lp.label,[normalizedAccidents,normalizedSnoOnGround])\n",
    "\n",
    "def getNormalizedRDD(nonNormalizedRDD): \n",
    "    \"\"\"Normalizes the features of the LabeldPoints contained in nonNormalizedRDD.\n",
    "\n",
    "    Args:\n",
    "        nonNormalizedRDD - RDD containing non-normalized features \n",
    "\n",
    "    Returns:\n",
    "        returnRDD: RDD containing normalized features\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    meanList = list()\n",
    "    stdevList = list()\n",
    "    numFeatures = len(nonNormalizedRDD.take(1)[0].features)\n",
    "    for i in range(0,numFeatures):\n",
    "        featureRDD = nonNormalizedRDD.map(lambda lp: lp.features[i])\n",
    "        featureMean = featureRDD.mean()\n",
    "        featureStdev = featureRDD.stdev()\n",
    "        meanList.insert(i,featureMean)\n",
    "        stdevList.insert(i,featureStdev)\n",
    "    global broadcastMean \n",
    "    broadcastMean = sc.broadcast(meanList)\n",
    "    global broadcastStdev \n",
    "    broadcastStdev = sc.broadcast(stdevList)\n",
    "    returnRDD = nonNormalizedRDD.map(normalizeFeatures)\n",
    "    return returnRDD\n",
    "\n",
    "normalizedSamplePoints = getNormalizedRDD(parsedPoints)\n",
    "print(normalizedSamplePoints.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ed6c6f0-fd0f-475a-ab65-e88e743030ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Apply linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe5f8f8-fbd0-450c-a6d5-02929501afb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713 206 919\n919\n"
     ]
    }
   ],
   "source": [
    "weights = [.8, .2] # train/test split\n",
    "seed = 42\n",
    "parsedTrainData, parsedValData = normalizedSamplePoints.randomSplit(weights,seed)\n",
    "parsedTrainData.cache()\n",
    "parsedValData.cache()\n",
    "nTrain = parsedTrainData.count()\n",
    "nVal = parsedValData.count()\n",
    "\n",
    "print(nTrain, nVal, nTrain + nVal)\n",
    "print(normalizedSamplePoints.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce3f1361-d596-41e8-ad2a-b7d348896e19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "# Values to use when training the linear regression model\n",
    "numIters = 500  # iterations\n",
    "alpha = 1.0  # step\n",
    "miniBatchFrac = 1.0  # miniBatchFraction\n",
    "reg = 1e-1  # regParam\n",
    "regType = 'l2'  # regType\n",
    "useIntercept = True  # intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ee6015c-e20b-4e05-b4c5-564b61f649d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/mllib/regression.py:367: FutureWarning: Deprecated in 2.0.0. Use ml.regression.LinearRegression.\n  warnings.warn(\"Deprecated in 2.0.0. Use ml.regression.LinearRegression.\", FutureWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10627993033097366,-0.16034459618798186,-0.2683340789856343,0.15560124587623536,-0.005662953317108078,0.14202668842758057] -79.77840401704017\n"
     ]
    }
   ],
   "source": [
    "firstModel = LinearRegressionWithSGD.train(parsedTrainData,numIters,alpha,miniBatchFrac,initialWeights=None,regParam=reg,regType=regType,intercept=useIntercept)\n",
    "\n",
    "# weightsLR1 stores the model weights; interceptLR1 stores the model intercept\n",
    "weightsLR1 = firstModel.weights\n",
    "interceptLR1 = firstModel.intercept\n",
    "print(weightsLR1, interceptLR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9f3f48-fd0d-4301-9550-b5539f4fe862",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(-87.739147556, [4.736608919573033,0.6614447817838677,-0.6602556323122132,-0.27573645879954267,1.9570253721791233,-0.3842492869745239]), LabeledPoint(-87.640270308, [-0.09194748318638288,0.09687504293802254,-0.6602556323122132,-0.27573645879954267,1.952293270256998,-0.3842492869745239]), LabeledPoint(-87.601787319, [-2.506225684566091,-0.5163854822549204,1.5145648913255074,-0.27573645879954267,1.9475611683348726,-0.3842492869745239]), LabeledPoint(-87.712760178, [-0.09194748318638288,1.0677243834214338,-0.6602556323122132,-0.27573645879954267,1.942829066412747,-0.3842492869745239]), LabeledPoint(-87.684592469, [-0.09194748318638288,1.8056911281919992,-0.6602556323122132,-0.27573645879954267,1.9380969644906216,-0.3842492869745239])]\n-79.3124486941125\n-79.73507482772948\n-80.47688279999872\n-79.8906916778441\n-80.00899385986223\n"
     ]
    }
   ],
   "source": [
    "samplePoints = parsedTrainData.take(5)\n",
    "print(samplePoints)\n",
    "for i in range(5):\n",
    "    samplePrediction = firstModel.predict(samplePoints[i].features)\n",
    "    print(samplePrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e0ba8ff-e42e-4e04-b5ce-9e0d69ab26e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.941125795237553\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def squaredError(label, prediction):\n",
    "    sqrError = (label-prediction)*(label-prediction)\n",
    "    return sqrError\n",
    "\n",
    "def calcRMSE(labelsAndPreds):\n",
    "    sqrSum = labelsAndPreds.map(lambda s: squaredError(s[0],s[1])).sum()\n",
    "    return math.sqrt(sqrSum/labelsAndPreds.count())\n",
    "\n",
    "labelsAndPreds = parsedValData.map(lambda lp: (lp.label,firstModel.predict(lp.features)))\n",
    "rmseValLR1 = calcRMSE(labelsAndPreds)\n",
    "\n",
    "#print(rmseValBase)\n",
    "print(rmseValLR1)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Traffic Crash Analysis (2)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
