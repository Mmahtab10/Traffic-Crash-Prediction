{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf2e8825-b1d2-4c6d-81ee-75c05f88d00c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Traffic Crash Analysis\n",
    "\n",
    "### Data importing and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c17149e-687f-4fda-b847-91bd4548eba6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting sodapy\n  Using cached sodapy-2.2.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: requests>=2.28.1 in /databricks/python3/lib/python3.10/site-packages (from sodapy) (2.28.1)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28.1->sodapy) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28.1->sodapy) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28.1->sodapy) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28.1->sodapy) (3.4)\nInstalling collected packages: sodapy\nSuccessfully installed sodapy-2.2.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install sodapy\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3229176b-3990-44da-9583-71919c5cd60e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "client = Socrata(\"data.cityofchicago.org\", None)\n",
    "\n",
    "# Specify the columns you want to retrieve\n",
    "desired_columns = \"crash_record_id,crash_date,crash_type,num_units,weather_condition,most_severe_injury,latitude,longitude\"\n",
    "\n",
    "results = client.get(\"85ca-t3if\", select=desired_columns, limit=800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eb8512f-928f-45de-8a07-38be8594f2e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790180\n+--------------------+--------------------+--------------------+------------+-------------+--------------------+---------+-----------------+\n|          crash_date|     crash_record_id|          crash_type|    latitude|    longitude|  most_severe_injury|num_units|weather_condition|\n+--------------------+--------------------+--------------------+------------+-------------+--------------------+---------+-----------------+\n|2023-12-17T00:09:...|9ae981e02784d3954...|INJURY AND / OR T...| 41.99343782|-87.802396002|NO INDICATION OF ...|        2|             RAIN|\n|2023-12-16T23:15:...|9574a24157fafae29...|NO INJURY / DRIVE...|41.806155683|-87.662618708|NO INDICATION OF ...|        5|  CLOUDY/OVERCAST|\n|2023-12-16T23:00:...|425066d3d6815e079...|NO INJURY / DRIVE...|41.959509273|-87.708341289|NO INDICATION OF ...|        3|             RAIN|\n|2023-12-16T22:58:...|5095111c15aa191a6...|INJURY AND / OR T...|41.964306938| -87.74776186|NO INDICATION OF ...|        1|             RAIN|\n|2023-12-16T22:50:...|2618bedfd3d0c3d1a...|INJURY AND / OR T...|41.927659564|-87.756936971|NO INDICATION OF ...|        1|             RAIN|\n+--------------------+--------------------+--------------------+------------+-------------+--------------------+---------+-----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Convert the results to a Spark DataFrame\n",
    "df2 = spark.createDataFrame(results)\n",
    "print(df2.count())\n",
    "# Show the first few rows of the DataFrame\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9fad5a2-1613-4cec-ae8e-1d128510cfbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create RDD of wanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d16fd3f-6dba-4801-8d28-537a47d1759f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----------------+--------------------+--------------------+-------------+-----------+\n|          Crash_type|num_units|Weather_condition|          Crash_date|  Most_severe_injury|    Longitude|   Latitude|\n+--------------------+---------+-----------------+--------------------+--------------------+-------------+-----------+\n|INJURY AND / OR T...|        2|             RAIN|2023-12-17T00:09:...|NO INDICATION OF ...|-87.802396002|41.99343782|\n+--------------------+---------+-----------------+--------------------+--------------------+-------------+-----------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "wanted_columns = df2.select(\"Crash_type\",\"num_units\",\"Weather_condition\",\"Crash_date\",\"Most_severe_injury\",\"Longitude\",\"Latitude\")\n",
    "wanted_columns.show(1)\n",
    "rdd_of_features = wanted_columns.rdd.map(lambda row:[row[0],row[1],row[2],row[3],row[4],row[5],row[6]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04cf460a-c0c5-4d25-b736-79f06b69fc19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Remove all rows where the content of one of the fields is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd8e8d5e-837d-4d7f-b335-4099e24b27db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790180\n740552\n"
     ]
    }
   ],
   "source": [
    "print(rdd_of_features.count())\n",
    "#row[0] = Crash_type, row[2] = Weather_condition,  row[4]= Most_severe_injury\n",
    "cleaned_data_rdd = rdd_of_features.filter(lambda row: row[0]!=\"UNKNOWN\"  and row[2]!=\"UNKNOWN\"  and row[4]!=\"UNKNOWN\" and row[5] != None and row[6] != None and row[0] != None and row[1] != None and row[2] != None and row[3] != None and row[4] != None)\n",
    "print(cleaned_data_rdd.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db499f2b-8f48-4a7d-8fb7-b399b739179d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Dataframe from RDD and get it ready for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b6a14eb-205d-441d-884b-f6aba0d71546",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('_1', 'string'), ('_2', 'string'), ('_3', 'string'), ('_4', 'string'), ('_5', 'string'), ('_6', 'string'), ('_7', 'string')]\n[('_1', 'string'), ('_2', 'double'), ('_3', 'string'), ('_4', 'string'), ('_5', 'string'), ('_6', 'double'), ('_7', 'double')]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73f5f3f9a35414ca8476fd6c3dedacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8951683701460f96d148a99b7e3974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---------------+--------------------+--------------------+-------------+------------+--------+--------+--------+--------+\n|                  _1| _2|             _3|                  _4|                  _5|           _6|          _7|_1_index|_3_index|_4_index|_5_index|\n+--------------------+---+---------------+--------------------+--------------------+-------------+------------+--------+--------+--------+--------+\n|INJURY AND / OR T...|2.0|           RAIN|2023-12-17T00:09:...|NO INDICATION OF ...|-87.802396002| 41.99343782|     1.0|     1.0|498688.0|     0.0|\n|NO INJURY / DRIVE...|5.0|CLOUDY/OVERCAST|2023-12-16T23:15:...|NO INDICATION OF ...|-87.662618708|41.806155683|     0.0|     3.0|498687.0|     0.0|\n|NO INJURY / DRIVE...|3.0|           RAIN|2023-12-16T23:00:...|NO INDICATION OF ...|-87.708341289|41.959509273|     0.0|     1.0|498686.0|     0.0|\n|INJURY AND / OR T...|1.0|           RAIN|2023-12-16T22:58:...|NO INDICATION OF ...| -87.74776186|41.964306938|     1.0|     1.0|498685.0|     0.0|\n|INJURY AND / OR T...|1.0|           RAIN|2023-12-16T22:50:...|NO INDICATION OF ...|-87.756936971|41.927659564|     1.0|     1.0|498684.0|     0.0|\n+--------------------+---+---------------+--------------------+--------------------+-------------+------------+--------+--------+--------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "cleaned_data_df = spark.createDataFrame(cleaned_data_rdd)\n",
    "\n",
    "#_1 = Crash_type, _2 = numUnits, _3 = weather, _4 = time, _5 = injury severity, _6 = longitude, _7 = latitude\n",
    "print(cleaned_data_df.dtypes)\n",
    "numeric_cols = [\"_2\", \"_6\", \"_7\"]\n",
    "for col_name in numeric_cols:    \n",
    "    cleaned_data_df = cleaned_data_df.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "print(cleaned_data_df.dtypes)\n",
    "\n",
    "string_cols = [\"_1\", \"_3\", \"_4\", \"_5\"]\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(cleaned_data_df) for column in string_cols ]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "indexed_df = pipeline.fit(cleaned_data_df).transform(cleaned_data_df)\n",
    "indexed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8198d30-38e7-452a-b063-3bb0fec0e10f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Labeled Points and Normalize features\n",
    "\n",
    "Partially taken from lab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd89cfb9-03ee-4929-9201-28fd888e7235",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(_1='INJURY AND / OR TOW DUE TO CRASH', _2=2.0, _3='RAIN', _4='2023-12-17T00:09:00.000', _5='NO INDICATION OF INJURY', _6=-87.802396002, _7=41.99343782, _1_index=1.0, _3_index=1.0, _4_index=498688.0, _5_index=0.0, features=DenseVector([2.0, -87.8024, 1.0, 1.0, 498688.0, 0.0]), scaledFeatures=DenseVector([0.0588, 0.0015, 1.0, 0.1, 1.0, 0.0]))]\n[Row(_1='INJURY AND / OR TOW DUE TO CRASH', _2=2.0, _3='RAIN', _4='2023-12-17T00:09:00.000', _5='NO INDICATION OF INJURY', _6=-87.802396002, _7=41.99343782, _1_index=1.0, _3_index=1.0, _4_index=498688.0, _5_index=0.0, features=DenseVector([2.0, -87.8024, 1.0, 1.0, 498688.0, 0.0]), scaledFeatures=DenseVector([0.0588, 0.0015, 1.0, 0.1, 1.0, 0.0]), label=41.99343782)]\n[0.058823529411764705,0.0015215230557074607,1.0,0.1,1.0,0.0] 41.99343782\n6\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler, StandardScaler\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "feature_column_names = [\"_2\", \"_1_index\", \"_3_index\", \"_4_index\", \"_5_index\"]\n",
    "\n",
    "# Assemble numeric columns into a feature vector\n",
    "assembler = VectorAssembler(inputCols=feature_column_names, outputCol=\"features\")\n",
    "vector_df = assembler.transform(indexed_df)\n",
    "\n",
    "useMinMaxScaler=True\n",
    "if (useMinMaxScaler):\n",
    "    # Apply MinMaxScaler\n",
    "    scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "    scalerModel = scaler.fit(vector_df)\n",
    "    scaledData = scalerModel.transform(vector_df)\n",
    "else:\n",
    "    # Apply StandarScaler\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "    scalerModel = scaler.fit(vector_df)\n",
    "    scaledData = scalerModel.transform(vector_df)\n",
    "\n",
    "normalizedSamplePoints = scaledData.withColumn(\"label\", col(\"_7\"))\n",
    "firstPoint = normalizedSamplePoints.take(1)\n",
    "print(firstPoint)\n",
    "print (firstPoint[0].scaledFeatures, firstPoint[0].label)\n",
    "print(len(firstPointFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe5f8f8-fbd0-450c-a6d5-02929501afb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592577 147975 740552\n"
     ]
    }
   ],
   "source": [
    "def to_labeled_point(row):\n",
    "    # Convert the DenseVector to a list for features\n",
    "    features_list = row.scaledFeatures.toArray().tolist()\n",
    "    return LabeledPoint(row['label'], features_list)\n",
    "\n",
    "weights = [.8, .2] # train/test split\n",
    "seed = 42\n",
    "\n",
    "# List of column names that are not needed in df, performance optimization for conversion to rdd later\n",
    "drop_columns = [\"_1\", \"_2\", \"_3\", \"_4\", \"_5\", \"_6\",\"_7\",\"_1_index\",\"_3_index\",\"_4_index\",\"_5_index\",\"features\"]\n",
    "normalizedSamplePoints=normalizedSamplePoints.drop(*drop_columns)\n",
    "parsedTrainData, parsedValData = normalizedSamplePoints.randomSplit(weights,seed)\n",
    "parsedTrainData=parsedTrainData.rdd.map(to_labeled_point)\n",
    "parsedValData=parsedValData.rdd.map(to_labeled_point)\n",
    "\n",
    "parsedTrainData.cache()\n",
    "parsedValData.cache()\n",
    "\n",
    "nTrain = parsedTrainData.count()\n",
    "nVal = parsedValData.count()\n",
    "\n",
    "print(nTrain, nVal, nTrain + nVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a4ba87c-f94d-4c2e-8bfe-d4daf774beeb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create baseline using the average value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5850b11d-0b29-4d5b-a352-370d4b0a688f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.85415196454593\n"
     ]
    }
   ],
   "source": [
    "averagelatitude = (parsedTrainData.map(lambda s: s.label)).mean()\n",
    "print(averagelatitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcd6a731-6c92-4d25-8392-2f5a88e48885",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33749975599488014\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def squaredError(label, prediction):\n",
    "    sqrError = (label-prediction)*(label-prediction)\n",
    "    return sqrError\n",
    "\n",
    "def calcRMSE(labelsAndPreds):\n",
    "    sqrSum = labelsAndPreds.map(lambda s: squaredError(s[0],s[1])).sum()\n",
    "    return math.sqrt(sqrSum/labelsAndPreds.count())\n",
    "\n",
    "labelsAndPredsTrain = parsedTrainData.map(lambda s: (s.label,averagelatitude))\n",
    "rmseTrainBase = calcRMSE(labelsAndPredsTrain)\n",
    "\n",
    "labelsAndPredsVal = parsedValData.map(lambda s: (s.label,averagelatitude))\n",
    "rmseValBase = calcRMSE(labelsAndPredsVal)\n",
    "print(rmseValBase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ed6c6f0-fd0f-475a-ab65-e88e743030ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Apply linear regression with weights version one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce3f1361-d596-41e8-ad2a-b7d348896e19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "# Values to use when training the linear regression model\n",
    "numIters = 500  # iterations\n",
    "alpha = 1.0  # step\n",
    "miniBatchFrac = 1.0  # miniBatchFraction\n",
    "reg = 1e-1  # regParam\n",
    "regType = 'l2'  # regType\n",
    "useIntercept = True  # intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ee6015c-e20b-4e05-b4c5-564b61f649d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "firstModel = LinearRegressionWithSGD.train(parsedTrainData,numIters,alpha,miniBatchFrac,initialWeights=None,regParam=reg,regType=regType,intercept=useIntercept)\n",
    "\n",
    "# weightsLR1 stores the model weights; interceptLR1 stores the model intercept\n",
    "weightsLR1 = firstModel.weights\n",
    "interceptLR1 = firstModel.intercept\n",
    "print(weightsLR1, interceptLR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9f3f48-fd0d-4301-9550-b5539f4fe862",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(41.953766077, [-2.271177215016908,-0.3438561969213648,1.623785064831159,-0.36501597422854265,-1.1113111841599141,1.2576563865428563]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,-0.6158442218212618,-0.36501597422854265,1.7722232272071285,-0.36406021416075135]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,-0.6158442218212618,-0.36501597422854265,2.0397628204068066,-0.36406021416075135]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,1.623785064831159,-0.36501597422854265,-0.3490794277634612,-0.36406021416075135]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,1.623785064831159,-0.36501597422854265,2.024769186913883,-0.36406021416075135])]\n38.18813280915872\n38.19151244587358\n38.191971052540744\n38.17996885753666\n38.18403802273387\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samplePoints = parsedValData.take(5)\n",
    "print(samplePoints)\n",
    "for i in range(5):\n",
    "    samplePrediction = firstModel.predict(samplePoints[i].features)\n",
    "    print(samplePrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e0ba8ff-e42e-4e04-b5ce-9e0d69ab26e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3375046806783204\n3.7677388192795545\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelsAndPreds = parsedValData.map(lambda lp: (lp.label,firstModel.predict(lp.features)))\n",
    "rmseValLR1 = calcRMSE(labelsAndPreds)\n",
    "\n",
    "print(rmseValBase)\n",
    "print(rmseValLR1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3607335-b7fa-4104-bc43-55ed7fe4c162",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Apply linear regression with weights 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb5092f-4861-40bf-bae8-516dca18a036",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numIters = 1000  # iterations\n",
    "alpha = 1.0  # step\n",
    "miniBatchFrac = 0.3  # miniBatchFraction\n",
    "reg = 1e-1  # regParam\n",
    "regType = 'l2'  # regType\n",
    "useIntercept = True  # intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87314f4e-eaa5-4025-acb1-726c460813d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0014663170739338547,-0.30519910377744236,-0.004721574114414496,0.004322624573910402,0.0029022498307462712,-0.0027006219689228333] 38.08705152877708\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "secondModel = LinearRegressionWithSGD.train(parsedTrainData,numIters,alpha,miniBatchFrac,initialWeights=None,regParam=reg,regType=regType,intercept=useIntercept)\n",
    "\n",
    "# weightsLR1 stores the model weights; interceptLR1 stores the model intercept\n",
    "weightsLR2 = secondModel.weights\n",
    "interceptLR2 = secondModel.intercept\n",
    "print(weightsLR2, interceptLR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43804139-70fc-4578-b73b-d939e4627e49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3375046806783204\n3.7677334504421314\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelsAndPreds = parsedValData.map(lambda lp: (lp.label,secondModel.predict(lp.features)))\n",
    "rmseValLR2 = calcRMSE(labelsAndPreds)\n",
    "\n",
    "print(rmseValBase)\n",
    "print(rmseValLR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c125c1ec-1216-4879-8ff5-9ae5567c148f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Random Forest Version One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2145917a-c256-4438-ac93-eb8799c97647",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.mllib.tree import RandomForest\n",
    "thirdModel = RandomForest.trainRegressor(parsedTrainData, categoricalFeaturesInfo={},\n",
    "                                      numTrees=8, featureSubsetStrategy=\"auto\",\n",
    "                                      impurity='variance', maxDepth=5, maxBins=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81979d1d-7177-43e8-8df1-a82f8a31405b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(41.953766077, [-2.271177215016908,-0.3438561969213648,1.623785064831159,-0.36501597422854265,-1.1113111841599141,1.2576563865428563]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,-0.6158442218212618,-0.36501597422854265,1.7722232272071285,-0.36406021416075135]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,-0.6158442218212618,-0.36501597422854265,2.0397628204068066,-0.36406021416075135]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,1.623785064831159,-0.36501597422854265,-0.3490794277634612,-0.36406021416075135]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,1.623785064831159,-0.36501597422854265,2.024769186913883,-0.36406021416075135])]\n41.89881648978902\n41.89423755284405\n41.89423755284405\n41.91018926780793\n41.90619244972316\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samplePoints = parsedValData.take(5)\n",
    "print(samplePoints)\n",
    "for i in range(5):\n",
    "    samplePrediction = thirdModel.predict(samplePoints[i].features)\n",
    "    print(samplePrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e6daa57-3abf-4bd5-a4cd-c026719687d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3375046806783204\n0.330398273614085\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "labels = parsedValData.map(lambda x: x.label).collect()\n",
    "predictions = thirdModel.predict(parsedValData.map(lambda x: x.features)).collect()\n",
    "rmseDT1 = np.sqrt(np.mean((np.array(predictions)-np.array(labels))**2))\n",
    "\n",
    "print(rmseValBase)\n",
    "print(rmseDT1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17a91e76-099a-4554-99b0-a8f43a314308",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Random Forest Version Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc811b0c-ff89-45e5-a873-be0e4193e986",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "thirdModel = RandomForest.trainRegressor(parsedTrainData, categoricalFeaturesInfo={},\n",
    "                                      numTrees=10, featureSubsetStrategy=\"auto\",\n",
    "                                      impurity='variance', maxDepth=6, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d90052f2-3452-42b2-a114-8093a1b495f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(41.953766077, [-2.271177215016908,-0.3438561969213648,1.623785064831159,-0.36501597422854265,-1.1113111841599141,1.2576563865428563]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,-0.6158442218212618,-0.36501597422854265,1.7722232272071285,-0.36406021416075135]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,-0.6158442218212618,-0.36501597422854265,2.0397628204068066,-0.36406021416075135]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,1.623785064831159,-0.36501597422854265,-0.3490794277634612,-0.36406021416075135]), LabeledPoint(41.976201139, [-2.271177215016908,-0.3311764777169709,1.623785064831159,-0.36501597422854265,2.024769186913883,-0.36406021416075135])]\n41.878382899264764\n41.89042959900137\n41.89042959900137\n41.87933583130467\n41.89256993244285\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samplePoints = parsedValData.take(5)\n",
    "print(samplePoints)\n",
    "for i in range(5):\n",
    "    samplePrediction = thirdModel.predict(samplePoints[i].features)\n",
    "    print(samplePrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44be81f7-4051-450a-a647-9c754c8a9594",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3375046806783204\n0.3334090623972566\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = parsedValData.map(lambda x: x.label).collect()\n",
    "predictions = thirdModel.predict(parsedValData.map(lambda x: x.features)).collect()\n",
    "rmseDT2 = np.sqrt(np.mean((np.array(predictions)-np.array(labels))**2))\n",
    "\n",
    "print(rmseValBase)\n",
    "print(rmseDT2)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Traffic Crash Analysis MinMax and StandardScaler",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
